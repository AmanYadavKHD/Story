class PDFDownloader:
    def __init__(self, driver: WebDriver, csv_writer, report_path):
        self.driver = driver
        self.csv_writer = csv_writer
        self.logger = logging.getLogger(__name__)
        self.existing_sites = self._load_existing_sites(report_path)
 
    def _load_existing_sites(self, report_path: Path) -> set:
        existing = set()
        if report_path.exists():
            with open(report_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                header = next(reader, None)
                if header and 'Site' in header:
                    site_index = header.index('Site')
                    for row in reader:
                        if len(row) > site_index:
                            existing.add(row[site_index])
        return existing
 
    def download_links(self, urls: list, output_dir: Path, company: str, query) -> None:
        output_dir.mkdir(parents=True, exist_ok=True)
 
        for idx, url in enumerate(urls, 1):
            pdf_name = ""
            status = "success"
            reason = ""
 
            if url in self.existing_sites:
                status = "skipped"
                reason = "Already downloaded"
                self.logger.info(f"Skipping already downloaded URL: {url}")
                self.csv_writer.writerow([company, "", url, query, status, reason])
                continue
 
            try:
                self.logger.info(f"Processing ({idx}/{len(urls)}): {url}")
 
                with requests.Session() as session:
                    session.max_redirects = 5
                    response = session.get(url, stream=True, timeout=15, allow_redirects=True)
 
                    content_type = response.headers.get('content-type', '').lower()
                    status_code = response.status_code
 
                    if status_code != 200:
                        status = "rejected"
                        reason = f"HTTP {status_code}"
                        self.logger.warning(f"Broken link ({status_code}): {url}")
 
                    elif 'pdf' not in content_type:
                        status = "rejected"
                        reason = f"Non-PDF content: {content_type}"
                        self.logger.warning(f"Skipping non-PDF content: {url} (Content-Type: {content_type})")
 
                    else:
                        filename = self._get_filename(response, url)
                        pdf_name = self._sanitize_filename(filename)
                        file_path = self._unique_path(output_dir / pdf_name)
 
                        with open(file_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                if chunk:
                                    f.write(chunk)
 
                        pdf_name = file_path.name
                        self.logger.info(f"Successfully saved: {file_path}")
 
            except Exception as e:
                status = "rejected"
                reason = str(e)[:100]
                self.logger.error(f"Failed to download {url}: {reason}", exc_info=True)
 
            finally:
                self.csv_writer.writerow([
                    company,
                    pdf_name or url.split('/')[-1],
                    url,
                    query,
                    status,
                    reason
                ])
 
    def _get_filename(self, response, url):
        cd = response.headers.get('content-disposition')
        if cd:
            try:
                filename = re.findall(r'filename\*?=["\']?(?:UTF-\d[\'"]*)?([^;\'\"]+)', cd, re.IGNORECASE)[0]
                return unquote(filename).strip()
            except (IndexError, UnicodeDecodeError):
                pass
 
        url_path = unquote(url.split('?')[0].split('/')[-1])
        return url_path or "document.pdf"
 
    def _sanitize_filename(self, filename):
        filename = filename.split('?')[0]
        filename = re.sub(r'[\\/*:"<>|]', "_", filename)
        if not filename.lower().endswith('.pdf'):
            filename += '.pdf'
        return filename
 
    def _unique_path(self, path):
        counter = 1
        orig_path = path
        while path.exists():
            path = orig_path.parent / f"{orig_path.stem}_{counter}{orig_path.suffix}"
            counter += 1
        return path
